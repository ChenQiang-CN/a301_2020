{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(landsat1)=\n",
    "# Landsat image processing 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@mommermiscience/dealing-with-geospatial-raster-data-in-python-with-rasterio-775e5ba0c9f5\n",
    "\n",
    "https://www.perrygeo.com/python-affine-transforms.html\n",
    "\n",
    "http://geologyandpython.com/get-landsat-8.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bulk image download from AWS\n",
    "\n",
    "Notes drawing on http://geologyandpython.com/get-landsat-8.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import a301_lib\n",
    "import datetime as dt\n",
    "import dateutil.parser\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_catalog=False\n",
    "if download_catalog:\n",
    "    s3_scenes = pd.read_csv('http://landsat-pds.s3.amazonaws.com/c1/L8/scene_list.gz', compression='gzip')\n",
    "else:\n",
    "    s3_scenes = pd.read_csv(a301_lib.sat_data / 'landsat/scene_list.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get images from Vancouver\n",
    "\n",
    "Filter out cloud cover > 20% and preprocessed images with ids ending in T2 or RT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path, row = 47, 26\n",
    "\n",
    "print('Path:',path, 'Row:', row)\n",
    "\n",
    "# Filter the Landsat Amazon S3 table for images matching path, row, cloudcover and processing state.\n",
    "scenes = s3_scenes[(s3_scenes.path == path) & (s3_scenes.row == row) & \n",
    "                   (s3_scenes.cloudCover <= 20) & \n",
    "                   (~s3_scenes.productId.str.contains('_T2')) &\n",
    "                   (~s3_scenes.productId.str.contains('_RT'))]\n",
    "print(' Found {} images\\n'.format(len(scenes)))\n",
    "scenes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes_van = pd.DataFrame(scenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = scenes_van.iloc[0].index\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = scenes_van.iloc[0].acquisitionDate\n",
    "timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_date = dateutil.parser.parse(timestamp)\n",
    "the_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_times(row):\n",
    "    return dateutil.parser.parse(row.acquisitionDate)\n",
    "\n",
    "the_times = scenes_van.apply(convert_times,axis=1)\n",
    "the_times.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes_van['datetime']=the_times\n",
    "del scenes_van['acquisitionDate']\n",
    "scenes_van.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes_van.datetime.iloc[0].day,scenes_van.datetime.iloc[0].month, scenes_van.datetime.iloc[0].year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_date(row):\n",
    "    year,month,day = row.datetime.year, row.datetime.month, row.datetime.day\n",
    "    the_date = dt.date(year,month,day)\n",
    "    return the_date\n",
    "date_vals = scenes_van.apply(make_date, axis=1)\n",
    "scenes_van['the_date']=date_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit = scenes_van.the_date == dt.date(2015,6,14)\n",
    "np.sum(hit)\n",
    "my_scene = scenes_van[hit]\n",
    "my_scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_url = my_scene.iloc[0].download_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "# Request the html text of the download_url from the amazon server. \n",
    "# download_url example: https://landsat-pds.s3.amazonaws.com/c1/L8/139/045/LC08_L1TP_139045_20170304_20170316_01_T1/index.html\n",
    "response = requests.get(scene_url)\n",
    "print(f\"response: {response}, {type(response)}\")\n",
    "landsat_path = Path() / 'landsat_scenes' / my_scene.iloc[0].productId\n",
    "landsat_path.mkdir(parents=True,exist_ok=True)\n",
    "# # If the response status code is fine (200)\n",
    "if response.status_code == 200:\n",
    "\n",
    "    # Import the html to beautiful soup\n",
    "    html = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Create the dir where we will put this image files.\n",
    "    entity_dir = os.path.join(landsat_path, my_scene.iloc[0].productId)\n",
    "    os.makedirs(entity_dir, exist_ok=True)\n",
    "\n",
    "    # Second loop: for each band of this image that we find using the html <li> tag\n",
    "    good_bands = ['B4.TIF', 'B5.TIF']\n",
    "    good_list = []\n",
    "    for li in html.find_all('li'):\n",
    "\n",
    "        # Get the href tag\n",
    "        the_file = li.find_next('a').get('href')\n",
    "        for keyword in good_bands:\n",
    "            if the_file.find(keyword) > 0:\n",
    "                good_list.append(the_file)\n",
    "        if the_file.find('MTL.txt') > 0:\n",
    "            good_list.append(the_file)\n",
    "    print(f\"here is goodlist: {good_list}\")\n",
    "    print(f\"here is mtl_file {mtl_file}\")\n",
    "        \n",
    "download=True\n",
    "if download:\n",
    "    for the_file in good_list:\n",
    "        print(f'  Downloading: {the_file}')\n",
    "\n",
    "        # Download the files\n",
    "        # code from: https://stackoverflow.com/a/18043472/5361345\n",
    "        image_path = scene_url.replace('index.html', the_file)\n",
    "        print(image_path)\n",
    "        response = requests.get(image_path, stream=True)\n",
    "\n",
    "        with open(landsat_path / the_file, 'wb') as output:\n",
    "            shutil.copyfileobj(response.raw, output)\n",
    "        del response\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "notebook_metadata_filter": "all,-language_info,-toc,-latex_envs",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.12,
    "jupytext_version": "1.6.0"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   13,
   18,
   27,
   33,
   42,
   46,
   52,
   58,
   72,
   76,
   81,
   86,
   91,
   99,
   105,
   109,
   118,
   125,
   129,
   184
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 4
}