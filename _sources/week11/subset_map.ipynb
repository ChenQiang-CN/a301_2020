{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pprint\n",
    "from pathlib import Path\n",
    "\n",
    "import cartopy\n",
    "import geopandas as gpd\n",
    "import pytz\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T20:39:57.801978Z",
     "iopub.status.busy": "2020-11-21T20:39:57.800746Z",
     "iopub.status.idle": "2020-11-21T20:40:00.091652Z",
     "shell.execute_reply": "2020-11-21T20:40:00.089999Z"
    }
   },
   "outputs": [],
   "source": [
    "import a301_lib\n",
    "\n",
    "pacific = pytz.timezone(\"US/Pacific\")\n",
    "date = datetime.datetime.today().astimezone(pacific)\n",
    "print(f\"written on {date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(subset_map)=\n",
    "# Finding shapefiles with fiona\n",
    "\n",
    "This notebook shows how to use fiona (used by geopandas) to subset big shapefiles\n",
    "for your landsat scene. To use this notebook edit these variables below\n",
    "\n",
    "    extent:  the lon/lat coords of your clipping region (can be bigger than your scene)\n",
    "    small_shapes:  the folder name you want the geojson written to\n",
    "    read_files:  set to True for the first pass, False later to read\n",
    "               from the geojson folder instead (much quicker)\n",
    "\n",
    "The shapefiles levels are described in the [Readme](https://github.com/phaustin/a301_2020/blob/master/notebooks/week11/Readme_gshhs_wdbII.md).\n",
    "\n",
    "Things to notice:\n",
    "\n",
    "1) how I use the filenames as dictionary keys for the dataframes\n",
    "2) how geopandas uses .cx  to slice by coordinate the find_features function\n",
    "3) how I create a figure in make_map and then add to it in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T20:40:00.110965Z",
     "iopub.status.busy": "2020-11-21T20:40:00.105738Z",
     "iopub.status.idle": "2020-11-21T20:40:18.624121Z",
     "shell.execute_reply": "2020-11-21T20:40:18.622876Z"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# customize extent, read_files and small_shapes here\n",
    "#\n",
    "# extent order (xleft, xright, ybot, ytop)\n",
    "extent = [130, 140, 30, 40]  # Osaka\n",
    "# extent = [-125, -115,35, 50]  #bc/washington/oregon\n",
    "read_files = True\n",
    "small_shapes = Path().home() / \"pha_shapes_asia\"\n",
    "#\n",
    "#\n",
    "#\n",
    "small_shapes.mkdir(exist_ok=True, parents=True)\n",
    "#\n",
    "# read either the original shape files or the subsetted\n",
    "# geojson files\n",
    "#\n",
    "gpd_dict = {}\n",
    "if read_files:\n",
    "    all_cia = a301_lib.data_share / \"openstreetmap/WDBII_shp/f\"\n",
    "    all_cia = list(all_cia.glob(\"*\"))\n",
    "    for item in all_cia:\n",
    "        gpd_dict[item.name] = gpd.read_file(item)\n",
    "        print(f\"read {item.name}\")\n",
    "\n",
    "    all_gshhs = a301_lib.data_share / \"openstreetmap/GSHHS_shp/f\"\n",
    "    all_gshhs = list(all_gshhs.glob(\"*\"))\n",
    "\n",
    "    for item in all_gshhs:\n",
    "        gpd_dict[item.name] = gpd.read_file(item)\n",
    "        print(f\"read {item.name}\")\n",
    "else:\n",
    "    shape_files = list(small_shapes.glob(\"*\"))\n",
    "    for item in shape_files:\n",
    "        key = item.stem\n",
    "        gpd_dict[key] = gpd.read_file(item)\n",
    "        print((f\"reading saved shapefile {item} with\\n\"\n",
    "               f\"{len(gpd_dict[key])} rows\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting\n",
    "\n",
    "In this cell I choose my extent in lon/lat coords and search for the\n",
    "rows that have features that fall inside the extent.  Geopandas has\n",
    "a special type of coordinate indexing (`.cx`), so that this:\n",
    "\n",
    "     hit_rows = df.cx[xleft:xright,ybot:ytop]\n",
    "\n",
    "runs ogr2ogr to clip the rows that are inside the bounding box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T20:40:18.631635Z",
     "iopub.status.busy": "2020-11-21T20:40:18.630362Z",
     "iopub.status.idle": "2020-11-21T20:40:18.633058Z",
     "shell.execute_reply": "2020-11-21T20:40:18.633673Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_features(extent, df):\n",
    "    \"\"\"\n",
    "    given an extent and a dataframe, return a new dataframe\n",
    "    containing only features that fall within the extent\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    extent:  list -- geographic extent in lon (deg E)/lat (deg N)\n",
    "    df:  the geopandas dataframe to slice\n",
    "    \"\"\"\n",
    "    xleft, xright, ybot, ytop = extent\n",
    "    hit_rows = df.cx[xleft:xright, ybot:ytop]\n",
    "    return hit_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use find_features to clip the shapefiles\n",
    "\n",
    "Keep only those frames that have shapes in the extent.  We only\n",
    "need to do this the first time we run the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T20:40:18.640163Z",
     "iopub.status.busy": "2020-11-21T20:40:18.639402Z",
     "iopub.status.idle": "2020-11-21T20:40:31.920411Z",
     "shell.execute_reply": "2020-11-21T20:40:31.918912Z"
    }
   },
   "outputs": [],
   "source": [
    "if read_files:\n",
    "    subset_dict = {}\n",
    "    for key, df in gpd_dict.items():\n",
    "        df_subset = find_features(extent, df)\n",
    "        if len(df_subset) > 0:\n",
    "            subset_dict[key] = df_subset\n",
    "            print(f\"clipping {key}\")\n",
    "else:\n",
    "    subset_dict=gpd_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T20:40:31.929059Z",
     "iopub.status.busy": "2020-11-21T20:40:31.927624Z",
     "iopub.status.idle": "2020-11-21T20:40:31.931711Z",
     "shell.execute_reply": "2020-11-21T20:40:31.930525Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_map(extent, figsize=(15, 15)):\n",
    "    \"\"\"\n",
    "    given an extent vector in the PlateCarre (lon/lat) projection,\n",
    "    make a map\n",
    "\n",
    "    Parameters:\n",
    "        extent:  list with [xbot, xtop, ybot, ytop]\n",
    "        figsize: (optional) figure size is inches\n",
    "\n",
    "    Returns:\n",
    "         fig, ax: cartopy figure and axis\n",
    "    \"\"\"\n",
    "    cartopy_crs = cartopy.crs.PlateCarree()\n",
    "    fig, ax = plt.subplots(\n",
    "        1, 1, figsize=figsize, subplot_kw={\"projection\": cartopy_crs}\n",
    "    )\n",
    "    ax.set_extent(extent, cartopy_crs)\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T20:40:31.941677Z",
     "iopub.status.busy": "2020-11-21T20:40:31.940913Z",
     "iopub.status.idle": "2020-11-21T20:40:33.917380Z",
     "shell.execute_reply": "2020-11-21T20:40:33.918765Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = make_map(extent)\n",
    "for key, df in subset_dict.items():\n",
    "    print(f\"adding {key} with {len(df)} features\")\n",
    "    if key.find(\"river\") > -1:\n",
    "        ax.add_geometries(\n",
    "            df[\"geometry\"], ax.projection, facecolor=\"none\", edgecolor=\"green\"\n",
    "        )\n",
    "    else:\n",
    "        ax.add_geometries(\n",
    "            df[\"geometry\"], ax.projection, facecolor=\"none\", edgecolor=\"blue\"\n",
    "        )\n",
    "gl = ax.gridlines(\n",
    "    crs=ax.projection,\n",
    "    draw_labels=True,\n",
    "    linewidth=2,\n",
    "    color=\"gray\",\n",
    "    alpha=0.5,\n",
    "    linestyle=\"--\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the dataframes as shape files for replotting\n",
    "\n",
    "This will write shape files into the `small_shapes` folder you defined at the top of the notebook.\n",
    "Each set of shapes is put into their own directory to keep things organized.\n",
    "\n",
    "To read these back in, set\n",
    "\n",
    "    read_files=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-21T20:40:33.959037Z",
     "iopub.status.busy": "2020-11-21T20:40:33.931335Z",
     "iopub.status.idle": "2020-11-21T20:40:35.543063Z",
     "shell.execute_reply": "2020-11-21T20:40:35.541853Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if read_files:\n",
    "    for key, df in subset_dict.items():\n",
    "        folder_name = small_shapes / key\n",
    "        folder_name.mkdir(exist_ok=True,parents=True)\n",
    "        curr_dir=Path()\n",
    "        os.chdir(folder_name)\n",
    "        df.to_file(folder_name)\n",
    "        print(f\"writing shapefiles to {folder_name}\")\n",
    "        os.chdir(curr_dir)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "all",
   "notebook_metadata_filter": "all,-language_info,-toc,-latex_envs",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.12,
    "jupytext_version": "1.6.0"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   16,
   27,
   40,
   61,
   107,
   119,
   141,
   148,
   167,
   195,
   222,
   233
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 4
}